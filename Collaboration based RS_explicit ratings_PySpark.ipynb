{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### starter code found at https://www.kaggle.com/vchulski/tutorial-collaborative-filtering-with-pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBLIB_TEMP_FOLDER=/tmp\n"
     ]
    }
   ],
   "source": [
    "# start Jupyter Notebook with this command - jupyter notebook --NotebookApp.iopub_data_rate_limit=100000000\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc #??? what's this for?\n",
    "\n",
    "%env JOBLIB_TEMP_FOLDER = /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.mllib.evaluation import RegressionMetrics, RankingMetrics\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark import SparkFiles\n",
    "\n",
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data - interactions for collaborative filtering, books for content filtering (too big?)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sp_interactions = spark.read.csv('goodreads_interactions.csv', header = True)\n",
    "sp_interactions.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# calculate sparsity\n",
    "numerator = sp_interactions.select(\"rating\").count()\n",
    "num_users = sp_interactions.select(\"user_id\").distinct().count()\n",
    "num_books = sp_interactions.select(\"book_id\").distinct().count()\n",
    "denominator = num_users * num_books\n",
    "sparsity = (1.0 - (numerator * 1.0)/denominator) * 100\n",
    "print(\"The sp_interactions dataframe is \", \"%.2f\" % sparsity + \"% empty.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Avg num ratings per book\n",
    "print(\"Avg num ratings per book: \")\n",
    "sp_interactions.groupBy(\"book_id\").count().select(avg(\"count\")).show()\n",
    "\n",
    "# Avg num ratings per users\n",
    "print(\"Avg num ratings per user: \")\n",
    "sp_interactions.groupBy(\"user_id\").count().select(avg(\"count\")).show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sp_interactions.printSchema()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sp_interactions = sp_interactions.select(sp_interactions.user_id.cast(\"integer\"),\n",
    "                                        sp_interactions.book_id.cast(\"integer\"),\n",
    "                                        sp_interactions.is_read.cast(\"integer\"),\n",
    "                                        sp_interactions.rating.cast(\"double\"),\n",
    "                                        sp_interactions.is_reviewed.cast(\"integer\"))\n",
    "sp_interactions.printSchema()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(training_data, test_data) = sp_interactions.randomSplit([0.80, 0.20], seed=307)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# continually failed\n",
    "model = cv.fit(training_data)\n",
    "best_model = model.bestModel\n",
    "predictions = best_model.transform(test_data)\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"**Best Model**\")\n",
    "print(\"RMSE = \"), rmse\n",
    "print(\" Rank: \"), best_model.rank\n",
    "print(\" MaxIter: \"), best_model._java_obj.parent().getMaxIter()\n",
    "print(\" RegParam: \"), best_model._java_obj.parent().getRegParam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------+--------+-----------+----------+-----------------+--------------------+-------------------------+--------------------+--------------------+-------------+--------------+-------------+------------------+-----------------------+---------+---------+---------+---------+---------+--------------------+--------------------+\n",
      "|book_id|goodreads_book_id|best_book_id| work_id|books_count|      isbn|           isbn13|             authors|original_publication_year|      original_title|               title|language_code|average_rating|ratings_count|work_ratings_count|work_text_reviews_count|ratings_1|ratings_2|ratings_3|ratings_4|ratings_5|           image_url|     small_image_url|\n",
      "+-------+-----------------+------------+--------+-----------+----------+-----------------+--------------------+-------------------------+--------------------+--------------------+-------------+--------------+-------------+------------------+-----------------------+---------+---------+---------+---------+---------+--------------------+--------------------+\n",
      "|      1|          2767052|     2767052| 2792775|        272| 439023483|9.78043902348e+12|     Suzanne Collins|                   2008.0|    The Hunger Games|The Hunger Games ...|          eng|          4.34|      4780653|           4942365|                 155254|    66715|   127936|   560092|  1481305|  2706317|https://images.gr...|https://images.gr...|\n",
      "|      2|                3|           3| 4640799|        491| 439554934|9.78043955493e+12|J.K. Rowling, Mar...|                   1997.0|Harry Potter and ...|Harry Potter and ...|          eng|          4.44|      4602479|           4800065|                  75867|    75504|   101676|   455024|  1156318|  3011543|https://images.gr...|https://images.gr...|\n",
      "|      3|            41865|       41865| 3212258|        226| 316015849|9.78031601584e+12|     Stephenie Meyer|                   2005.0|            Twilight|Twilight (Twiligh...|        en-US|          3.57|      3866839|           3916824|                  95009|   456191|   436802|   793319|   875073|  1355439|https://images.gr...|https://images.gr...|\n",
      "|      4|             2657|        2657| 3275794|        487|  61120081|9.78006112008e+12|          Harper Lee|                   1960.0|To Kill a Mocking...|To Kill a Mocking...|          eng|          4.25|      3198671|           3340896|                  72586|    60427|   117415|   446835|  1001952|  1714267|https://images.gr...|https://images.gr...|\n",
      "|      5|             4671|        4671|  245494|       1356| 743273567|9.78074327356e+12| F. Scott Fitzgerald|                   1925.0|    The Great Gatsby|    The Great Gatsby|          eng|          3.89|      2683664|           2773745|                  51992|    86236|   197621|   606158|   936012|   947718|https://images.gr...|https://images.gr...|\n",
      "|      6|         11870085|    11870085|16827462|        226| 525478817|9.78052547881e+12|          John Green|                   2012.0|The Fault in Our ...|The Fault in Our ...|          eng|          4.26|      2346404|           2478609|                 140739|    47994|    92723|   327550|   698471|  1311871|https://images.gr...|https://images.gr...|\n",
      "|      7|             5907|        5907| 1540236|        969| 618260307| 9.7806182603e+12|      J.R.R. Tolkien|                   1937.0|The Hobbit or The...|          The Hobbit|        en-US|          4.25|      2071616|           2196809|                  37653|    46023|    76784|   288649|   665635|  1119718|https://images.gr...|https://images.gr...|\n",
      "|      8|             5107|        5107| 3036731|        360| 316769177|9.78031676917e+12|       J.D. Salinger|                   1951.0|The Catcher in th...|The Catcher in th...|          eng|          3.79|      2044241|           2120637|                  44920|   109383|   185520|   455042|   661516|   709176|https://images.gr...|https://images.gr...|\n",
      "|      9|              960|         960| 3338963|        311|1416524797|9.78141652479e+12|           Dan Brown|                   2000.0|    Angels & Demons |Angels & Demons  ...|        en-CA|          3.85|      2001311|           2078754|                  25112|    77841|   145740|   458429|   716569|   680175|https://images.gr...|https://images.gr...|\n",
      "|     10|             1885|        1885| 3060926|       3455| 679783261|9.78067978327e+12|         Jane Austen|                   1813.0| Pride and Prejudice| Pride and Prejudice|          eng|          4.24|      2035490|           2191465|                  49152|    54700|    86485|   284852|   609755|  1155673|https://images.gr...|https://images.gr...|\n",
      "|     11|            77203|       77203| 3295919|        283|1594480001|   9.78159448e+12|     Khaled Hosseini|                   2003.0|    The Kite Runner |     The Kite Runner|          eng|          4.26|      1813044|           1878095|                  59730|    34288|    59980|   226062|   628174|   929591|https://images.gr...|https://images.gr...|\n",
      "|     12|         13335037|    13335037|13155899|        210|  62024035|9.78006202404e+12|       Veronica Roth|                   2011.0|           Divergent|Divergent (Diverg...|          eng|          4.24|      1903563|           2216814|                 101023|    36315|    82870|   310297|   673028|  1114304|https://images.gr...|https://images.gr...|\n",
      "|     13|             5470|        5470|  153313|        995| 451524934|9.78045152494e+12|George Orwell, Er...|                   1949.0|Nineteen Eighty-Four|                1984|          eng|          4.14|      1956832|           2053394|                  45518|    41845|    86425|   324874|   692021|   908229|https://images.gr...|https://images.gr...|\n",
      "|     14|             7613|        7613| 2207778|        896| 452284244|9.78045228424e+12|       George Orwell|                   1945.0|Animal Farm: A Fa...|         Animal Farm|          eng|          3.87|      1881700|           1982987|                  35472|    66854|   135147|   433432|   698642|   648912|https://images.gr...|https://images.gr...|\n",
      "|     15|            48855|       48855| 3532896|        710| 553296981|9.78055329698e+12|Anne Frank, Elean...|                   1947.0|Het Achterhuis: D...|The Diary of a Yo...|          eng|           4.1|      1972666|           2024493|                  20825|    45225|    91270|   355756|   656870|   875372|https://images.gr...|https://images.gr...|\n",
      "|     16|          2429135|     2429135| 1708725|        274| 307269752|9.78030726975e+12|Stieg Larsson, Re...|                   2005.0|MÃ¤n som hatar kvi...|The Girl with the...|          eng|          4.11|      1808403|           1929834|                  62543|    54835|    86051|   285413|   667485|   836050|https://images.gr...|https://images.gr...|\n",
      "|     17|          6148028|     6148028| 6171458|        201| 439023491| 9.7804390235e+12|     Suzanne Collins|                   2009.0|       Catching Fire|Catching Fire (Th...|          eng|           4.3|      1831039|           1988079|                  88538|    10492|    48030|   262010|   687238|   980309|https://images.gr...|https://images.gr...|\n",
      "|     18|                5|           5| 2402163|        376|043965548X|9.78043965548e+12|J.K. Rowling, Mar...|                   1999.0|Harry Potter and ...|Harry Potter and ...|          eng|          4.53|      1832823|           1969375|                  36099|     6716|    20413|   166129|   509447|  1266670|https://images.gr...|https://images.gr...|\n",
      "|     19|               34|          34| 3204327|        566| 618346252|9.78061834626e+12|      J.R.R. Tolkien|                   1954.0| The Fellowship o...|The Fellowship of...|          eng|          4.34|      1766803|           1832541|                  15333|    38031|    55862|   202332|   493922|  1042394|https://images.gr...|https://images.gr...|\n",
      "|     20|          7260188|     7260188| 8812783|        239| 439023513|9.78043902351e+12|     Suzanne Collins|                   2010.0|          Mockingjay|Mockingjay (The H...|          eng|          4.03|      1719760|           1870748|                  96274|    30144|   110498|   373060|   618271|   738775|https://images.gr...|https://images.gr...|\n",
      "+-------+-----------------+------------+--------+-----------+----------+-----------------+--------------------+-------------------------+--------------------+--------------------+-------------+--------------+-------------+------------------+-----------------------+---------+---------+---------+---------+---------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# continued failures led me to trim back on size of dataset - choose 10k\n",
    "books10k = spark.read.csv('books10k.csv', header = True)\n",
    "books10k.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "|user_id|book_id|rating|\n",
      "+-------+-------+------+\n",
      "|      1|    258|     5|\n",
      "|      2|   4081|     4|\n",
      "|      2|    260|     5|\n",
      "|      2|   9296|     5|\n",
      "|      2|   2318|     3|\n",
      "|      2|     26|     4|\n",
      "|      2|    315|     3|\n",
      "|      2|     33|     4|\n",
      "|      2|    301|     5|\n",
      "|      2|   2686|     5|\n",
      "|      2|   3753|     5|\n",
      "|      2|   8519|     5|\n",
      "|      4|     70|     4|\n",
      "|      4|    264|     3|\n",
      "|      4|    388|     4|\n",
      "|      4|     18|     5|\n",
      "|      4|     27|     5|\n",
      "|      4|     21|     5|\n",
      "|      4|      2|     5|\n",
      "|      4|     23|     5|\n",
      "+-------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# continued failures led me to trim back on size of dataset - choose 10k\n",
    "ratings10k = spark.read.csv('ratings10k.csv', header = True)\n",
    "ratings10k.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratings10k dataframe is  98.94% empty.\n"
     ]
    }
   ],
   "source": [
    "# calculate sparsity\n",
    "numerator = ratings10k.select(\"rating\").count()\n",
    "num_users = ratings10k.select(\"user_id\").distinct().count()\n",
    "num_books = ratings10k.select(\"book_id\").distinct().count()\n",
    "denominator = num_users * num_books\n",
    "sparsity = (1.0 - (numerator * 1.0)/denominator) * 100\n",
    "print(\"The ratings10k dataframe is \", \"%.2f\" % sparsity + \"% empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg num ratings per book: \n",
      "+-----------------+\n",
      "|       avg(count)|\n",
      "+-----------------+\n",
      "|40.15235939404492|\n",
      "+-----------------+\n",
      "\n",
      "Avg num ratings per user: \n",
      "+-----------------+\n",
      "|       avg(count)|\n",
      "+-----------------+\n",
      "|60.87513199577614|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Avg num ratings per book\n",
    "print(\"Avg num ratings per book: \")\n",
    "ratings10k.groupBy(\"book_id\").count().select(avg(\"count\")).show()\n",
    "\n",
    "# Avg num ratings per users\n",
    "print(\"Avg num ratings per user: \")\n",
    "ratings10k.groupBy(\"user_id\").count().select(avg(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- book_id: integer (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings10k = ratings10k.select(ratings10k.user_id.cast(\"integer\"),\n",
    "                                        ratings10k.book_id.cast(\"integer\"),\n",
    "                                        ratings10k.rating.cast(\"float\"))\n",
    "ratings10k.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "|user_id|book_id|rating|\n",
      "+-------+-------+------+\n",
      "|    463|    471|   4.0|\n",
      "|    463|    148|   0.0|\n",
      "|    463|   2142|   0.0|\n",
      "|    463|   3997|   0.0|\n",
      "|    463|    496|   0.0|\n",
      "|    463|   1580|   0.0|\n",
      "|    463|   2366|   0.0|\n",
      "|    463|    463|   0.0|\n",
      "|    463|   1238|   0.0|\n",
      "|    463|    833|   0.0|\n",
      "|    463|   1088|   0.0|\n",
      "|    463|   6620|   0.0|\n",
      "|    463|   1591|   0.0|\n",
      "|    463|   9852|   0.0|\n",
      "|    463|   4101|   0.0|\n",
      "|    463|   3918|   0.0|\n",
      "|    463|   6397|   0.0|\n",
      "|    463|   1342|   0.0|\n",
      "|    463|   7253|   0.0|\n",
      "|    463|   3794|   0.0|\n",
      "+-------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# correct the format to include zeros\n",
    "\n",
    "users = ratings10k.select(\"user_id\").distinct()\n",
    "books = ratings10k.select(\"book_id\").distinct()\n",
    "\n",
    "# Cross join users and products\n",
    "cj = users.crossJoin(books)\n",
    "ratings = cj.join(ratings10k, [\"user_id\", \"book_id\"], \"left\").fillna(0)\n",
    "ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, test) = ratings.randomSplit([0.80, 0.20], seed=731)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 0.39640662340632277)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_model = ALS(userCol = \"user_id\", itemCol = \"book_id\", ratingCol = \"rating\",\n",
    "               nonnegative = True,\n",
    "               coldStartStrategy = \"drop\",\n",
    "               implicitPrefs = False)\n",
    "model = als_model.fit(train)\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName = 'rmse', labelCol = 'rating',\n",
    "                               predictionCol = 'prediction')\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"RMSE: \"), rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+------------+\n",
      "|user_id|book_id|rating|  prediction|\n",
      "+-------+-------+------+------------+\n",
      "|   1645|    148|   4.0| 0.049995024|\n",
      "|   3175|    148|   0.0|  0.05377537|\n",
      "|   3918|    148|   0.0|   0.1438313|\n",
      "|   5300|    148|   0.0| 0.065395646|\n",
      "|   1025|    148|   0.0| 0.051750187|\n",
      "|   1127|    148|   0.0|  0.07879922|\n",
      "|   1507|    148|   0.0|  0.16217102|\n",
      "|   2387|    148|   0.0| 0.017485976|\n",
      "|   2563|    148|   0.0|  0.01884679|\n",
      "|   3475|    148|   0.0|  0.03814276|\n",
      "|   4190|    148|   0.0| 0.064677484|\n",
      "|   4929|    148|   0.0|  0.03870188|\n",
      "|   1143|    148|   0.0|   0.1420587|\n",
      "|   3000|    148|   0.0|8.5675006E-4|\n",
      "|    808|    148|   0.0|  0.09464113|\n",
      "|   1265|    148|   0.0|  0.05013421|\n",
      "|   3098|    148|   0.0|  0.03183744|\n",
      "|   4078|    148|   0.0|  0.07300787|\n",
      "|   4684|    148|   0.0|  0.09861391|\n",
      "|   5223|    148|   0.0|  0.15989798|\n",
      "+-------+-------+------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweak model by playing with rank, MaxIter, RegParam, goal = lowest RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 0.40559786366728084)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change rank only (chose 16 b/c it was recommended by Goodreads paper)\n",
    "als_model2 = ALS(userCol = \"user_id\", itemCol = \"book_id\", ratingCol = \"rating\",\n",
    "                 rank = 16, maxIter = 10, regParam = 1,\n",
    "               nonnegative = True,\n",
    "               coldStartStrategy = \"drop\",\n",
    "               implicitPrefs = False)\n",
    "model2 = als_model2.fit(train)\n",
    "predictions2 = model2.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName = 'rmse', labelCol = 'rating',\n",
    "                               predictionCol = 'prediction')\n",
    "rmse2 = evaluator.evaluate(predictions2)\n",
    "print(\"RMSE: \"), rmse2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+----------+\n",
      "|user_id|book_id|rating|prediction|\n",
      "+-------+-------+------+----------+\n",
      "|   1645|    148|   4.0|       0.0|\n",
      "|   3175|    148|   0.0|       0.0|\n",
      "|   3918|    148|   0.0|       0.0|\n",
      "|   5300|    148|   0.0|       0.0|\n",
      "|   1025|    148|   0.0|       0.0|\n",
      "|   1127|    148|   0.0|       0.0|\n",
      "|   1507|    148|   0.0|       0.0|\n",
      "|   2387|    148|   0.0|       0.0|\n",
      "|   2563|    148|   0.0|       0.0|\n",
      "|   3475|    148|   0.0|       0.0|\n",
      "|   4190|    148|   0.0|       0.0|\n",
      "|   4929|    148|   0.0|       0.0|\n",
      "|   1143|    148|   0.0|       0.0|\n",
      "|   3000|    148|   0.0|       0.0|\n",
      "|    808|    148|   0.0|       0.0|\n",
      "|   1265|    148|   0.0|       0.0|\n",
      "|   3098|    148|   0.0|       0.0|\n",
      "|   4078|    148|   0.0|       0.0|\n",
      "|   4684|    148|   0.0|       0.0|\n",
      "|   5223|    148|   0.0|       0.0|\n",
      "+-------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num models to be tested:  32\n"
     ]
    }
   ],
   "source": [
    "param_grid = ParamGridBuilder().addGrid(als_model.rank, [5, 10, 15, 20]).addGrid(als_model.maxIter, [5, 10]).addGrid(als_model.regParam, [0.01, 0.05, 0.1, 0.15]).build()\n",
    "evaluator = RegressionEvaluator(metricName = \"rmse\", labelCol = \"rating\",\n",
    "                               predictionCol = \"prediction\")\n",
    "cv = CrossValidator(estimator = als_model,\n",
    "                   estimatorParamMaps = param_grid,\n",
    "                   evaluator = evaluator,\n",
    "                   numFolds = 5)\n",
    "print (\"Num models to be tested: \", len(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcv = cv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.ml.recommendation.ALSModel'>\n"
     ]
    }
   ],
   "source": [
    "best_model = modelcv.bestModel\n",
    "print(type(best_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3622062135603919\n"
     ]
    }
   ],
   "source": [
    "test_predictions = best_model.transform(test)\n",
    "rmse = evaluator.evaluate(test_predictions)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(best_model.rank) # k value (# of latent features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "0.01\n"
     ]
    }
   ],
   "source": [
    "print(best_model._java_obj.parent().getMaxIter())\n",
    "print(best_model._java_obj.parent().getRegParam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model: k = 25, maxIter = 10, regParam = 0.01, RMSE = 0.3622"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+-----------+\n",
      "|user_id|book_id|rating| prediction|\n",
      "+-------+-------+------+-----------+\n",
      "|   1645|    148|   4.0| 0.70989245|\n",
      "|   3175|    148|   0.0| 0.15258428|\n",
      "|   3918|    148|   0.0| 0.71268547|\n",
      "|   5300|    148|   0.0|   0.302438|\n",
      "|   1025|    148|   0.0|   0.245731|\n",
      "|   1127|    148|   0.0| 0.13814119|\n",
      "|   1507|    148|   0.0| 0.27556774|\n",
      "|   2387|    148|   0.0| 0.13265418|\n",
      "|   2563|    148|   0.0|   0.218646|\n",
      "|   3475|    148|   0.0| 0.22585842|\n",
      "|   4190|    148|   0.0| 0.69588304|\n",
      "|   4929|    148|   0.0| 0.15377276|\n",
      "|   1143|    148|   0.0| 0.58321583|\n",
      "|   3000|    148|   0.0|0.012677923|\n",
      "|    808|    148|   0.0| 0.49552304|\n",
      "|   1265|    148|   0.0|  0.0973807|\n",
      "|   3098|    148|   0.0| 0.16174576|\n",
      "|   4078|    148|   0.0| 0.02927421|\n",
      "|   4684|    148|   0.0|0.107607946|\n",
      "|   5223|    148|   0.0|  0.9644963|\n",
      "+-------+-------+------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|user_id|     recommendations|\n",
      "+-------+--------------------+\n",
      "|   1580|[[11, 1.0400147],...|\n",
      "|   5300|[[37, 2.0233123],...|\n",
      "|   1591|[[167, 0.19397956...|\n",
      "|   4101|[[11, 1.3917072],...|\n",
      "|   1342|[[476, 0.63664454...|\n",
      "|   2122|[[4, 1.1893904], ...|\n",
      "|    463|[[7, 4.087946], [...|\n",
      "|    833|[[94, 1.4590017],...|\n",
      "|   3794|[[168, 1.8770207]...|\n",
      "|   1645|[[11, 2.7405286],...|\n",
      "|   3175|[[19, 4.241493], ...|\n",
      "|   2366|[[205, 4.1261687]...|\n",
      "|   5156|[[65, 3.4123454],...|\n",
      "|   3997|[[10, 0.30373782]...|\n",
      "|   1238|[[11, 3.7416406],...|\n",
      "|   3918|[[50, 4.152341], ...|\n",
      "|   4818|[[26, 1.1737348],...|\n",
      "|   5518|[[125, 1.6194955]...|\n",
      "|   1829|[[50, 1.9392428],...|\n",
      "|   3749|[[168, 0.92164904...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view recommendations\n",
    "userRecs = best_model.recommendForAllUsers(10)\n",
    "userRecs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 60's Ratings:\n",
      "+-------+-------+------+\n",
      "|user_id|book_id|rating|\n",
      "+-------+-------+------+\n",
      "|      2|    260|   5.0|\n",
      "|      2|   3753|   5.0|\n",
      "|      2|   9296|   5.0|\n",
      "|      2|   8519|   5.0|\n",
      "|      2|   2686|   5.0|\n",
      "|      2|    301|   5.0|\n",
      "|      2|   4081|   4.0|\n",
      "|      2|     33|   4.0|\n",
      "|      2|     26|   4.0|\n",
      "|      2|   2318|   3.0|\n",
      "|      2|    315|   3.0|\n",
      "|      2|    471|   0.0|\n",
      "|      2|    496|   0.0|\n",
      "|      2|    148|   0.0|\n",
      "|      2|   1580|   0.0|\n",
      "|      2|   1238|   0.0|\n",
      "|      2|   2142|   0.0|\n",
      "|      2|   2366|   0.0|\n",
      "|      2|    833|   0.0|\n",
      "|      2|   3997|   0.0|\n",
      "+-------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "User 60s Recommendations:\n",
      "+-------+--------------------+\n",
      "|user_id|     recommendations|\n",
      "+-------+--------------------+\n",
      "|      2|[[11, 0.77537215]...|\n",
      "+-------+--------------------+\n",
      "\n",
      "User 63's Ratings:\n",
      "+-------+-------+------+\n",
      "|user_id|book_id|rating|\n",
      "+-------+-------+------+\n",
      "|     63|    323|   5.0|\n",
      "|     63|   6772|   5.0|\n",
      "|     63|    592|   5.0|\n",
      "|     63|   7151|   5.0|\n",
      "|     63|   4475|   5.0|\n",
      "|     63|   8455|   5.0|\n",
      "|     63|     80|   5.0|\n",
      "|     63|   3913|   4.0|\n",
      "|     63|     85|   4.0|\n",
      "|     63|   1113|   4.0|\n",
      "|     63|    498|   4.0|\n",
      "|     63|   4531|   4.0|\n",
      "|     63|   6160|   4.0|\n",
      "|     63|    709|   4.0|\n",
      "|     63|    614|   4.0|\n",
      "|     63|    485|   4.0|\n",
      "|     63|    162|   4.0|\n",
      "|     63|   5374|   4.0|\n",
      "|     63|   9858|   4.0|\n",
      "|     63|    669|   4.0|\n",
      "+-------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "User 63's Recommendations:\n",
      "+-------+--------------------+\n",
      "|user_id|     recommendations|\n",
      "+-------+--------------------+\n",
      "|     63|[[58, 2.5218172],...|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at user 60's ratings\n",
    "print(\"User 2's Ratings:\")\n",
    "ratings.filter(col(\"user_id\") == 2).sort(\"rating\", ascending = False).show()\n",
    "\n",
    "# Look at the movies recommended to user 60\n",
    "print(\"User 2's Recommendations:\")\n",
    "userRecs.filter(col(\"user_id\") == 2).show()\n",
    "\n",
    "# Look at user 63's ratings\n",
    "print(\"User 63's Ratings:\")\n",
    "ratings.filter(col(\"user_id\") == 63).sort(\"rating\", ascending = False).show()\n",
    "\n",
    "# Look at the movies recommended to user 63\n",
    "print(\"User 63's Recommendations:\")\n",
    "userRecs.filter(col(\"user_id\") == 63).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve '`book_id_and_ratings.book_id`' given input columns: [exploded_table.book_ids_and_ratings, als_recs_temp.recommendations, als_recs_temp.user_id]; line 1 pos 16;\n'Project [user_id#35822, 'book_id_and_ratings.book_id AS book_id#37377, book_ids_and_ratings#37379.rating AS prediction#37378]\n+- Generate explode(recommendations#35823), false, exploded_table, [book_ids_and_ratings#37379]\n   +- SubqueryAlias als_recs_temp\n      +- Project [id#35818 AS user_id#35822, cast(recommendations#35819 as array<struct<book_id:int,rating:float>>) AS recommendations#35823]\n         +- Project [key#35812 AS id#35818, TopByKeyAggregator(scala.Tuple3)#35817 AS recommendations#35819]\n            +- Aggregate [value#35804], [value#35804 AS key#35812, topbykeyaggregator(org.apache.spark.ml.recommendation.TopByKeyAggregator@741a1359, Some(newInstance(class scala.Tuple3)), Some(class scala.Tuple3), Some(StructType(StructField(_1,IntegerType,false), StructField(_2,IntegerType,false), StructField(_3,FloatType,false))), encodeusingserializer(input[0, java.lang.Object, true], true), decodeusingserializer(input[0, binary, true], org.apache.spark.util.BoundedPriorityQueue, true), mapobjects(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 2178), if (isnull(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 2178))) null else named_struct(_1, knownnotnull(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 2178))._1, _2, knownnotnull(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 2178))._2), input[0, [Lscala.Tuple2;, true], None), ArrayType(StructType(StructField(_1,IntegerType,false), StructField(_2,FloatType,false)),true), true, 0, 0) AS TopByKeyAggregator(scala.Tuple3)#35817]\n               +- AppendColumns org.apache.spark.ml.recommendation.ALSModel$$Lambda$3666/0x00000008013da840@5b6ca3f3, class scala.Tuple3, [StructField(_1,IntegerType,false), StructField(_2,IntegerType,false), StructField(_3,FloatType,false)], newInstance(class scala.Tuple3), [input[0, int, false] AS value#35804]\n                  +- SerializeFromObject [knownnotnull(assertnotnull(input[0, scala.Tuple3, true]))._1 AS _1#35793, knownnotnull(assertnotnull(input[0, scala.Tuple3, true]))._2 AS _2#35794, knownnotnull(assertnotnull(input[0, scala.Tuple3, true]))._3 AS _3#35795]\n                     +- MapPartitions org.apache.spark.sql.Dataset$$Lambda$3664/0x00000008013dd040@611de7d0, obj#35792: scala.Tuple3\n                        +- DeserializeToObject newInstance(class scala.Tuple2), obj#35791: scala.Tuple2\n                           +- Join Cross\n                              :- SerializeFromObject [mapobjects(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 2157), if (isnull(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 2157))) null else named_struct(_1, knownnotnull(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 2157))._1, _2, staticinvoke(class org.apache.spark.sql.catalyst.expressions.UnsafeArrayData, ArrayType(FloatType,false), fromPrimitiveArray, knownnotnull(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 2157))._2, true, false)), input[0, scala.collection.Seq, true], None) AS value#35771]\n                              :  +- MapPartitions org.apache.spark.ml.recommendation.ALSModel$$Lambda$3649/0x0000000801361040@45b9b071, obj#35770: scala.collection.Seq\n                              :     +- DeserializeToObject newInstance(class scala.Tuple2), obj#35769: scala.Tuple2\n                              :        +- Project [_1#35541 AS id#35546, _2#35542 AS features#35547]\n                              :           +- SerializeFromObject [knownnotnull(assertnotnull(input[0, scala.Tuple2, true]))._1 AS _1#35541, staticinvoke(class org.apache.spark.sql.catalyst.expressions.UnsafeArrayData, ArrayType(FloatType,false), fromPrimitiveArray, knownnotnull(assertnotnull(input[0, scala.Tuple2, true]))._2, true, false) AS _2#35542]\n                              :              +- ExternalRDD [obj#35540]\n                              +- SerializeFromObject [mapobjects(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 2160), if (isnull(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 2160))) null else named_struct(_1, knownnotnull(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 2160))._1, _2, staticinvoke(class org.apache.spark.sql.catalyst.expressions.UnsafeArrayData, ArrayType(FloatType,false), fromPrimitiveArray, knownnotnull(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 2160))._2, true, false)), input[0, scala.collection.Seq, true], None) AS value#35780]\n                                 +- MapPartitions org.apache.spark.ml.recommendation.ALSModel$$Lambda$3649/0x0000000801361040@42a098be, obj#35779: scala.collection.Seq\n                                    +- DeserializeToObject newInstance(class scala.Tuple2), obj#35778: scala.Tuple2\n                                       +- Project [_1#35553 AS id#35558, _2#35554 AS features#35559]\n                                          +- SerializeFromObject [knownnotnull(assertnotnull(input[0, scala.Tuple2, true]))._1 AS _1#35553, staticinvoke(class org.apache.spark.sql.catalyst.expressions.UnsafeArrayData, ArrayType(FloatType,false), fromPrimitiveArray, knownnotnull(assertnotnull(input[0, scala.Tuple2, true]))._2, true, false) AS _2#35554]\n                                             +- ExternalRDD [obj#35552]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-8ebfce5ce504>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0muserRecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregisterTempTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ALS_recs_temp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclean_recs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SELECT user_id, book_id_and_ratings.book_id AS book_id,book_ids_and_ratings.rating AS prediction FROM ALS_recs_temp LATERAL VIEW explode(recommendations) exploded_table AS book_ids_and_ratings\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \"\"\"\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve '`book_id_and_ratings.book_id`' given input columns: [exploded_table.book_ids_and_ratings, als_recs_temp.recommendations, als_recs_temp.user_id]; line 1 pos 16;\n'Project [user_id#35822, 'book_id_and_ratings.book_id AS book_id#37377, book_ids_and_ratings#37379.rating AS prediction#37378]\n+- Generate explode(recommendations#35823), false, exploded_table, [book_ids_and_ratings#37379]\n   +- SubqueryAlias als_recs_temp\n      +- Project [id#35818 AS user_id#35822, cast(recommendations#35819 as array<struct<book_id:int,rating:float>>) AS recommendations#35823]\n         +- Project [key#35812 AS id#35818, TopByKeyAggregator(scala.Tuple3)#35817 AS recommendations#35819]\n            +- Aggregate [value#35804], [value#35804 AS key#35812, topbykeyaggregator(org.apache.spark.ml.recommendation.TopByKeyAggregator@741a1359, Some(newInstance(class scala.Tuple3)), Some(class scala.Tuple3), Some(StructType(StructField(_1,IntegerType,false), StructField(_2,IntegerType,false), StructField(_3,FloatType,false))), encodeusingserializer(input[0, java.lang.Object, true], true), decodeusingserializer(input[0, binary, true], org.apache.spark.util.BoundedPriorityQueue, true), mapobjects(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 2178), if (isnull(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 2178))) null else named_struct(_1, knownnotnull(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 2178))._1, _2, knownnotnull(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 2178))._2), input[0, [Lscala.Tuple2;, true], None), ArrayType(StructType(StructField(_1,IntegerType,false), StructField(_2,FloatType,false)),true), true, 0, 0) AS TopByKeyAggregator(scala.Tuple3)#35817]\n               +- AppendColumns org.apache.spark.ml.recommendation.ALSModel$$Lambda$3666/0x00000008013da840@5b6ca3f3, class scala.Tuple3, [StructField(_1,IntegerType,false), StructField(_2,IntegerType,false), StructField(_3,FloatType,false)], newInstance(class scala.Tuple3), [input[0, int, false] AS value#35804]\n                  +- SerializeFromObject [knownnotnull(assertnotnull(input[0, scala.Tuple3, true]))._1 AS _1#35793, knownnotnull(assertnotnull(input[0, scala.Tuple3, true]))._2 AS _2#35794, knownnotnull(assertnotnull(input[0, scala.Tuple3, true]))._3 AS _3#35795]\n                     +- MapPartitions org.apache.spark.sql.Dataset$$Lambda$3664/0x00000008013dd040@611de7d0, obj#35792: scala.Tuple3\n                        +- DeserializeToObject newInstance(class scala.Tuple2), obj#35791: scala.Tuple2\n                           +- Join Cross\n                              :- SerializeFromObject [mapobjects(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 2157), if (isnull(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 2157))) null else named_struct(_1, knownnotnull(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 2157))._1, _2, staticinvoke(class org.apache.spark.sql.catalyst.expressions.UnsafeArrayData, ArrayType(FloatType,false), fromPrimitiveArray, knownnotnull(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 2157))._2, true, false)), input[0, scala.collection.Seq, true], None) AS value#35771]\n                              :  +- MapPartitions org.apache.spark.ml.recommendation.ALSModel$$Lambda$3649/0x0000000801361040@45b9b071, obj#35770: scala.collection.Seq\n                              :     +- DeserializeToObject newInstance(class scala.Tuple2), obj#35769: scala.Tuple2\n                              :        +- Project [_1#35541 AS id#35546, _2#35542 AS features#35547]\n                              :           +- SerializeFromObject [knownnotnull(assertnotnull(input[0, scala.Tuple2, true]))._1 AS _1#35541, staticinvoke(class org.apache.spark.sql.catalyst.expressions.UnsafeArrayData, ArrayType(FloatType,false), fromPrimitiveArray, knownnotnull(assertnotnull(input[0, scala.Tuple2, true]))._2, true, false) AS _2#35542]\n                              :              +- ExternalRDD [obj#35540]\n                              +- SerializeFromObject [mapobjects(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 2160), if (isnull(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 2160))) null else named_struct(_1, knownnotnull(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 2160))._1, _2, staticinvoke(class org.apache.spark.sql.catalyst.expressions.UnsafeArrayData, ArrayType(FloatType,false), fromPrimitiveArray, knownnotnull(lambdavariable(MapObject, ObjectType(class scala.Tuple2), true, 2160))._2, true, false)), input[0, scala.collection.Seq, true], None) AS value#35780]\n                                 +- MapPartitions org.apache.spark.ml.recommendation.ALSModel$$Lambda$3649/0x0000000801361040@42a098be, obj#35779: scala.collection.Seq\n                                    +- DeserializeToObject newInstance(class scala.Tuple2), obj#35778: scala.Tuple2\n                                       +- Project [_1#35553 AS id#35558, _2#35554 AS features#35559]\n                                          +- SerializeFromObject [knownnotnull(assertnotnull(input[0, scala.Tuple2, true]))._1 AS _1#35553, staticinvoke(class org.apache.spark.sql.catalyst.expressions.UnsafeArrayData, ArrayType(FloatType,false), fromPrimitiveArray, knownnotnull(assertnotnull(input[0, scala.Tuple2, true]))._2, true, false) AS _2#35554]\n                                             +- ExternalRDD [obj#35552]\n"
     ]
    }
   ],
   "source": [
    "userRecs.registerTempTable(\"ALS_recs_temp\")\n",
    "clean_recs = spark.sql(\"SELECT user_id, book_id, rating_id, original_title \n",
    "                       AS book_id, book_ids_and_ratings.rating AS prediction FROM ALS_recs_temp LATERAL VIEW explode(recommendations) exploded_table AS book_ids_and_ratings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+\n",
      "|user_id|         BookRec|\n",
      "+-------+----------------+\n",
      "|   1580| [11, 1.0400147]|\n",
      "|   1580|[33, 0.65387654]|\n",
      "|   1580|[100, 0.5300547]|\n",
      "|   1580|[38, 0.52326894]|\n",
      "|   1580| [67, 0.4987593]|\n",
      "|   1580|[57, 0.47979054]|\n",
      "|   1580|[45, 0.47413552]|\n",
      "|   1580| [4, 0.46988013]|\n",
      "|   1580| [22, 0.4662242]|\n",
      "|   1580|[26, 0.45919847]|\n",
      "|   5300| [37, 2.0233123]|\n",
      "|   5300| [58, 1.9057353]|\n",
      "|   5300| [59, 1.7356001]|\n",
      "|   5300|  [29, 1.725448]|\n",
      "|   5300|[138, 1.6259873]|\n",
      "|   5300| [50, 1.6185813]|\n",
      "|   5300|[102, 1.6020172]|\n",
      "|   5300| [15, 1.5831457]|\n",
      "|   5300|[117, 1.5628898]|\n",
      "|   5300| [85, 1.5290784]|\n",
      "+-------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exploded_recs = spark.sql(\"SELECT user_id, explode(recommendations) AS BookRec FROM ALS_recs_temp\")\n",
    "exploded_recs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_recs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-7442e1b6d5c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclean_recs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbook_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'book_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_recs' is not defined"
     ]
    }
   ],
   "source": [
    "clean_recs.join(book_info, ['book_id'], 'left').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clean_recs.join(book_ratings, ['user_id', 'book_id'], 'left').filter(book_ratings.ratings.isNull(().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add full book data to see if it changes the model (does this become content based?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- book_id: string (nullable = true)\n",
      " |-- goodreads_book_id: string (nullable = true)\n",
      " |-- best_book_id: string (nullable = true)\n",
      " |-- work_id: string (nullable = true)\n",
      " |-- books_count: string (nullable = true)\n",
      " |-- isbn: string (nullable = true)\n",
      " |-- isbn13: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- original_publication_year: string (nullable = true)\n",
      " |-- original_title: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- language_code: string (nullable = true)\n",
      " |-- average_rating: string (nullable = true)\n",
      " |-- ratings_count: string (nullable = true)\n",
      " |-- work_ratings_count: string (nullable = true)\n",
      " |-- work_text_reviews_count: string (nullable = true)\n",
      " |-- ratings_1: string (nullable = true)\n",
      " |-- ratings_2: string (nullable = true)\n",
      " |-- ratings_3: string (nullable = true)\n",
      " |-- ratings_4: string (nullable = true)\n",
      " |-- ratings_5: string (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- small_image_url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books10k.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- book_id: integer (nullable = true)\n",
      " |-- work_id: integer (nullable = true)\n",
      " |-- books_count: integer (nullable = true)\n",
      " |-- original_publication_year: integer (nullable = true)\n",
      " |-- average_rating: float (nullable = true)\n",
      " |-- ratings_count: integer (nullable = true)\n",
      " |-- work_ratings_count: integer (nullable = true)\n",
      " |-- work_text_reviews_count: integer (nullable = true)\n",
      " |-- ratings_1: integer (nullable = true)\n",
      " |-- ratings_2: integer (nullable = true)\n",
      " |-- ratings_3: integer (nullable = true)\n",
      " |-- ratings_4: integer (nullable = true)\n",
      " |-- ratings_5: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books10k = books10k.select(books10k.book_id.cast(\"integer\"),\n",
    "                                        books10k.work_id.cast(\"integer\"),\n",
    "                                        books10k.books_count.cast(\"integer\"),\n",
    "                                        books10k.original_publication_year.cast(\"integer\"),\n",
    "                                        books10k.average_rating.cast(\"float\"),\n",
    "                                        books10k.ratings_count.cast(\"integer\"),\n",
    "                                        books10k.work_ratings_count.cast(\"integer\"),\n",
    "                                        books10k.work_text_reviews_count.cast(\"integer\"),\n",
    "                                        books10k.ratings_1.cast(\"integer\"),\n",
    "                                        books10k.ratings_2.cast(\"integer\"),\n",
    "                                        books10k.ratings_3.cast(\"integer\"),\n",
    "                                        books10k.ratings_4.cast(\"integer\"),\n",
    "                                        books10k.ratings_5.cast(\"integer\"))\n",
    "books10k.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------+-------------------------+--------------+-------------+------------------+-----------------------+---------+---------+---------+---------+---------+-------+------+\n",
      "|book_id|work_id|books_count|original_publication_year|average_rating|ratings_count|work_ratings_count|work_text_reviews_count|ratings_1|ratings_2|ratings_3|ratings_4|ratings_5|user_id|rating|\n",
      "+-------+-------+-----------+-------------------------+--------------+-------------+------------------+-----------------------+---------+---------+---------+---------+---------+-------+------+\n",
      "|      1|2792775|        272|                     2008|           4.0|      4780653|           4942365|                 155254|    66715|   127936|   560092|  1481305|  2706317|   2886|   5.0|\n",
      "|      2|4640799|        491|                     1997|           4.0|      4602479|           4800065|                  75867|    75504|   101676|   455024|  1156318|  3011543|   5670|   5.0|\n",
      "|      2|4640799|        491|                     1997|           4.0|      4602479|           4800065|                  75867|    75504|   101676|   455024|  1156318|  3011543|   5760|   5.0|\n",
      "|      2|4640799|        491|                     1997|           4.0|      4602479|           4800065|                  75867|    75504|   101676|   455024|  1156318|  3011543|   5748|   4.0|\n",
      "|      2|4640799|        491|                     1997|           4.0|      4602479|           4800065|                  75867|    75504|   101676|   455024|  1156318|  3011543|   4371|   4.0|\n",
      "|      2|4640799|        491|                     1997|           4.0|      4602479|           4800065|                  75867|    75504|   101676|   455024|  1156318|  3011543|   4075|   5.0|\n",
      "|      2|4640799|        491|                     1997|           4.0|      4602479|           4800065|                  75867|    75504|   101676|   455024|  1156318|  3011543|   5739|   5.0|\n",
      "|      2|4640799|        491|                     1997|           4.0|      4602479|           4800065|                  75867|    75504|   101676|   455024|  1156318|  3011543|   5731|   4.0|\n",
      "|      2|4640799|        491|                     1997|           4.0|      4602479|           4800065|                  75867|    75504|   101676|   455024|  1156318|  3011543|   5730|   5.0|\n",
      "|      2|4640799|        491|                     1997|           4.0|      4602479|           4800065|                  75867|    75504|   101676|   455024|  1156318|  3011543|   5665|   4.0|\n",
      "|      2|4640799|        491|                     1997|           4.0|      4602479|           4800065|                  75867|    75504|   101676|   455024|  1156318|  3011543|   5082|   4.0|\n",
      "|      2|4640799|        491|                     1997|           4.0|      4602479|           4800065|                  75867|    75504|   101676|   455024|  1156318|  3011543|   4661|   4.0|\n",
      "|      2|4640799|        491|                     1997|           4.0|      4602479|           4800065|                  75867|    75504|   101676|   455024|  1156318|  3011543|   1792|   4.0|\n",
      "|      2|4640799|        491|                     1997|           4.0|      4602479|           4800065|                  75867|    75504|   101676|   455024|  1156318|  3011543|   2373|   4.0|\n",
      "|      2|4640799|        491|                     1997|           4.0|      4602479|           4800065|                  75867|    75504|   101676|   455024|  1156318|  3011543|   5717|   4.0|\n",
      "|      2|4640799|        491|                     1997|           4.0|      4602479|           4800065|                  75867|    75504|   101676|   455024|  1156318|  3011543|   5712|   4.0|\n",
      "|      2|4640799|        491|                     1997|           4.0|      4602479|           4800065|                  75867|    75504|   101676|   455024|  1156318|  3011543|   2991|   3.0|\n",
      "|      2|4640799|        491|                     1997|           4.0|      4602479|           4800065|                  75867|    75504|   101676|   455024|  1156318|  3011543|   5685|   4.0|\n",
      "|      2|4640799|        491|                     1997|           4.0|      4602479|           4800065|                  75867|    75504|   101676|   455024|  1156318|  3011543|   5681|   4.0|\n",
      "|      2|4640799|        491|                     1997|           4.0|      4602479|           4800065|                  75867|    75504|   101676|   455024|  1156318|  3011543|   5678|   5.0|\n",
      "+-------+-------+-----------+-------------------------+--------------+-------------+------------------+-----------------------+---------+---------+---------+---------+---------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books = books10k.join(ratings10k, ['book_id'], \"left\").fillna(0)\n",
    "books.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train2, test2) = books.randomSplit([0.80, 0.20], seed=731)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+-----------+\n",
      "|user_id|book_id|rating| prediction|\n",
      "+-------+-------+------+-----------+\n",
      "|   1645|    148|   4.0| 0.70989245|\n",
      "|   3175|    148|   0.0| 0.15258428|\n",
      "|   3918|    148|   0.0| 0.71268547|\n",
      "|   5300|    148|   0.0|   0.302438|\n",
      "|   1025|    148|   0.0|   0.245731|\n",
      "|   1127|    148|   0.0| 0.13814119|\n",
      "|   1507|    148|   0.0| 0.27556774|\n",
      "|   2387|    148|   0.0| 0.13265418|\n",
      "|   2563|    148|   0.0|   0.218646|\n",
      "|   3475|    148|   0.0| 0.22585842|\n",
      "|   4190|    148|   0.0| 0.69588304|\n",
      "|   4929|    148|   0.0| 0.15377276|\n",
      "|   1143|    148|   0.0| 0.58321583|\n",
      "|   3000|    148|   0.0|0.012677923|\n",
      "|    808|    148|   0.0| 0.49552304|\n",
      "|   1265|    148|   0.0|  0.0973807|\n",
      "|   3098|    148|   0.0| 0.16174576|\n",
      "|   4078|    148|   0.0| 0.02927421|\n",
      "|   4684|    148|   0.0|0.107607946|\n",
      "|   5223|    148|   0.0|  0.9644963|\n",
      "+-------+-------+------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute '_jdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-1d61698c55e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m evaluator = RegressionEvaluator(metricName = 'rmse', labelCol = 'rating',\n\u001b[1;32m     10\u001b[0m                                predictionCol = 'prediction')\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mrmse_book\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbook_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RMSE: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse_book\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \"\"\"\n\u001b[1;32m    101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0misLargerBetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute '_jdf'"
     ]
    }
   ],
   "source": [
    "# use parameters from best_model (k = 25, maxIter = 10, regParam = 0.01), RMSE = 0.3622\n",
    "als_bookModel = ALS(userCol = \"user_id\", itemCol = \"book_id\", ratingCol = \"rating\",\n",
    "                 rank = 25, maxIter = 10, regParam = 0.01,\n",
    "               nonnegative = True,\n",
    "               coldStartStrategy = \"drop\",\n",
    "               implicitPrefs = False)\n",
    "book_model = als_bookModel.fit(train)\n",
    "book_pred = book_model.transform(test).show()\n",
    "evaluator = RegressionEvaluator(metricName = 'rmse', labelCol = 'rating',\n",
    "                               predictionCol = 'prediction')\n",
    "rmse_book = evaluator.evaluate(book_pred)\n",
    "print(\"RMSE: \"), rmse_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# change data to Spark format - or can I read it in using json? csv?\n",
    "book_schema = StructType([\n",
    "    StructField('isbn', IntegerType(), False),\n",
    "    StructField('text_reviews_count',IntegerType(), False),\n",
    "    StructField('series',IntegerType(), False),\n",
    "    StructField('country_code',StringType(), False),\n",
    "    StructField('language_code',StringType(), False),\n",
    "    StructField('popular_shelves',MapType('name'), False),\n",
    "    StructField('asin',UnknownType(), False),\n",
    "    StructField('is_ebook',StringType(), False),\n",
    "    StructField('average_rating',FloatType(), False),\n",
    "    StructField('kindle_asin',StringType(), False),\n",
    "    StructField('similar_books',UnknownType(), False),\n",
    "    StructField('description',LongType(), False),\n",
    "    StructField('format',StringType(), False),\n",
    "    StructField('link',LongType(), False),\n",
    "    StructField('authors',UnknownType(), False),\n",
    "    StructField('publisher',StringType(), False),\n",
    "    StructField('num_pages', IntegerType(), False),\n",
    "    StructField('publication_day',IntegerType(), False),\n",
    "    StructField('isbn13',IntegerType(), False),\n",
    "    StructField('publication_month',IntegerType(), False),\n",
    "    StructField('edition_information',UnknownType(), False),\n",
    "    StructField('publication_year',IntegerType(), False),\n",
    "    StructField('url',LongType(), False),\n",
    "    StructField('image_url',LongType(), False),\n",
    "    StructField('book_id',IntegerType(), False),\n",
    "    StructField('ratings_count',IntegerType(), False),\n",
    "    StructField('work_id',IntegerType(), False),\n",
    "    StructField('title',StringType(), False),\n",
    "    StructField('title_without_series',StringType(), False)\n",
    "])\n",
    "sp_book = spark.read.json('goodreads_books.json', header = True).cache() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
